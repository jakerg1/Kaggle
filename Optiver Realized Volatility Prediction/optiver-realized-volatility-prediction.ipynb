{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":27233,"databundleVersionId":2344753,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Imports, loading samples, finding dimensions, and printing columns.","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \n\nbook_sample = pd.read_parquet('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0', engine = 'pyarrow')\ntrade_sample = pd.read_parquet('/kaggle/input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0', engine = 'pyarrow')\ntrain_target = pd.read_csv('/kaggle/input/optiver-realized-volatility-prediction/train.csv')\n\nprint('book_train sample dimensions:', book_sample.shape)\nprint('trade_train sample dimensions:', trade_sample.shape)\nprint('train.csv dimensions:', train_target.shape)\n\nprint('book_train columns:', book_sample.columns.tolist())\nprint('trade_train columns:', trade_sample.columns.tolist())\nprint('train.csv columns:', train_target.columns.tolist())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-30T21:18:01.106365Z","iopub.execute_input":"2025-04-30T21:18:01.106788Z","iopub.status.idle":"2025-04-30T21:18:02.341152Z","shell.execute_reply.started":"2025-04-30T21:18:01.106763Z","shell.execute_reply":"2025-04-30T21:18:02.339992Z"}},"outputs":[{"name":"stdout","text":"book_train sample dimensions: (917553, 10)\ntrade_train sample dimensions: (123443, 5)\ntrain.csv dimensions: (428932, 3)\nbook_train columns: ['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2']\ntrade_train columns: ['time_id', 'seconds_in_bucket', 'price', 'size', 'order_count']\ntrain.csv columns: ['stock_id', 'time_id', 'target']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Using duckdb to get some sql practice and to make data exploration easier\n- stock_id: ID number for each of the 112 stocks in the dataset\n- time_id: Index for each 10-minute trading window during the day.\n- avg_spread: Average (ask price – bid price) across the window (in dollars). Wider spreads mean market makers are unsure = future price swings often larger.\n- mid_price_vol: Standard deviation of the mid-price (1/2 (ask+bid)) inside the window. Captures how “jittery” prices already were; choppy windows tend to stay volatile.\n- order_imbalance: Net size leaning to buyers vs sellers, Range ≈ –1 to +1. Strong imbalance (big positive or negative) can trigger jumps when the pressure releases.\n- trade_logret_std: Std dev of trade-to-trade log-returns within the window. (Micro-volatility seen in executed trades.) Direct glimpse of recent realised volatility. Higher values usually mean the next window will also be lively.","metadata":{}},{"cell_type":"code","source":"import duckdb\nimport pyarrow.parquet as pq\n\nsql = \"\"\"\nWITH book AS (\n  SELECT\n    stock_id,\n    time_id,\n    AVG(ask_price1 - bid_price1) AS avg_spread,\n    STDDEV((ask_price1 + bid_price1) * 0.5) AS mid_price_vol,\n    SUM(ask_size1 - bid_size1) * 1.0 /\n    NULLIF(SUM(ask_size1 + bid_size1), 0) AS order_imbalance\n  FROM read_parquet('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*/*.parquet')\n  GROUP BY stock_id, time_id\n),\n\ntrade_ret AS (\n  SELECT\n    stock_id,\n    time_id,\n    LN(price) - LN(LAG(price) OVER (\n        PARTITION BY stock_id, time_id ORDER BY seconds_in_bucket\n    )) AS log_ret\n  FROM read_parquet('/kaggle/input/optiver-realized-volatility-prediction/trade_train.parquet/*/*.parquet')\n),\n\ntrade AS (\n  SELECT\n    stock_id,\n    time_id,\n    STDDEV(log_ret) AS trade_logret_std\n  FROM trade_ret\n  WHERE log_ret IS NOT NULL\n  GROUP BY stock_id, time_id\n)\n\n/* ---------- FINAL TABLE ---------- */\nSELECT\n  b.stock_id,\n  b.time_id,\n  b.avg_spread,\n  b.mid_price_vol,\n  b.order_imbalance,\n  t.trade_logret_std\nFROM book AS b\nLEFT JOIN trade AS t\nUSING (stock_id, time_id)\n\"\"\"\n\nprint(\"Running aggregation …\")\nfeatures = duckdb.query(sql).to_df()\nfeatures.to_parquet(\"features.parquet\")   # cache for later use\n\nprint(\"Done – shape:\", features.shape)\nfeatures.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T21:54:20.033070Z","iopub.execute_input":"2025-04-30T21:54:20.034899Z","iopub.status.idle":"2025-04-30T21:54:39.337412Z","shell.execute_reply.started":"2025-04-30T21:54:20.034842Z","shell.execute_reply":"2025-04-30T21:54:39.336360Z"}},"outputs":[{"name":"stdout","text":"Running aggregation …\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a7c21a5a07e42d19850eee690c1771b"}},"metadata":{}},{"name":"stdout","text":"Done – shape: (428932, 6)\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"   stock_id  time_id  avg_spread  mid_price_vol  order_imbalance  \\\n0         0      103    0.001039       0.001901        -0.319490   \n1         0      128    0.000659       0.000921        -0.154892   \n2         0      159    0.000600       0.001411        -0.280426   \n3         0      266    0.000783       0.000894        -0.079256   \n4         0      289    0.000459       0.000584         0.022822   \n\n   trade_logret_std  \n0          0.000362  \n1          0.000368  \n2          0.000263  \n3          0.000385  \n4          0.000181  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stock_id</th>\n      <th>time_id</th>\n      <th>avg_spread</th>\n      <th>mid_price_vol</th>\n      <th>order_imbalance</th>\n      <th>trade_logret_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>103</td>\n      <td>0.001039</td>\n      <td>0.001901</td>\n      <td>-0.319490</td>\n      <td>0.000362</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>128</td>\n      <td>0.000659</td>\n      <td>0.000921</td>\n      <td>-0.154892</td>\n      <td>0.000368</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>159</td>\n      <td>0.000600</td>\n      <td>0.001411</td>\n      <td>-0.280426</td>\n      <td>0.000263</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>266</td>\n      <td>0.000783</td>\n      <td>0.000894</td>\n      <td>-0.079256</td>\n      <td>0.000385</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>289</td>\n      <td>0.000459</td>\n      <td>0.000584</td>\n      <td>0.022822</td>\n      <td>0.000181</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"markdown","source":"- Loaded feature tabel\n- Combined featurs with train.csv\n- Picked out labels and features","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\nfeatures = pd.read_parquet(\"features.parquet\")      # (≈4 M × 6)\n\ntrain_target = pd.read_csv(\n    \"/kaggle/input/optiver-realized-volatility-prediction/train.csv\",\n    usecols=[\"stock_id\", \"time_id\", \"target\"]\n)\n\ndata = features.merge(train_target, on=[\"stock_id\", \"time_id\"])\nprint(\"Merged shape:\", data.shape)\ndisplay(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T21:55:06.094436Z","iopub.execute_input":"2025-04-30T21:55:06.095011Z","iopub.status.idle":"2025-04-30T21:55:06.435740Z","shell.execute_reply.started":"2025-04-30T21:55:06.094977Z","shell.execute_reply":"2025-04-30T21:55:06.434745Z"}},"outputs":[{"name":"stdout","text":"Merged shape: (428932, 7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   stock_id  time_id  avg_spread  mid_price_vol  order_imbalance  \\\n0         0      103    0.001039       0.001901        -0.319490   \n1         0      128    0.000659       0.000921        -0.154892   \n2         0      159    0.000600       0.001411        -0.280426   \n3         0      266    0.000783       0.000894        -0.079256   \n4         0      289    0.000459       0.000584         0.022822   \n\n   trade_logret_std    target  \n0          0.000362  0.004120  \n1          0.000368  0.003702  \n2          0.000263  0.002077  \n3          0.000385  0.004280  \n4          0.000181  0.003784  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stock_id</th>\n      <th>time_id</th>\n      <th>avg_spread</th>\n      <th>mid_price_vol</th>\n      <th>order_imbalance</th>\n      <th>trade_logret_std</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>103</td>\n      <td>0.001039</td>\n      <td>0.001901</td>\n      <td>-0.319490</td>\n      <td>0.000362</td>\n      <td>0.004120</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>128</td>\n      <td>0.000659</td>\n      <td>0.000921</td>\n      <td>-0.154892</td>\n      <td>0.000368</td>\n      <td>0.003702</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>159</td>\n      <td>0.000600</td>\n      <td>0.001411</td>\n      <td>-0.280426</td>\n      <td>0.000263</td>\n      <td>0.002077</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>266</td>\n      <td>0.000783</td>\n      <td>0.000894</td>\n      <td>-0.079256</td>\n      <td>0.000385</td>\n      <td>0.004280</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>289</td>\n      <td>0.000459</td>\n      <td>0.000584</td>\n      <td>0.022822</td>\n      <td>0.000181</td>\n      <td>0.003784</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"- Adds a baseline-volatility feature","metadata":{}},{"cell_type":"code","source":"data['stock_mean_target'] = (\n    data.groupby('stock_id')['target']\n        .transform('mean')\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T22:05:01.105014Z","iopub.execute_input":"2025-04-30T22:05:01.105397Z","iopub.status.idle":"2025-04-30T22:05:01.138512Z","shell.execute_reply.started":"2025-04-30T22:05:01.105363Z","shell.execute_reply":"2025-04-30T22:05:01.137646Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"- Mid-price column: add mid_price = (ask + bid) / 2.\n- for each (stock_id, time_id) get first and last mid-price.\n- compute % change (mid_price_change).","metadata":{}},{"cell_type":"code","source":"from glob import glob\n\nbook_paths = glob(\n    '/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*/*.parquet'\n)\n\ncols = ['stock_id', 'time_id', 'seconds_in_bucket', 'ask_price1', 'bid_price1']\nbook_list = [pq.read_table(p, columns=cols).to_pandas() for p in book_paths]\nbook_raw  = pd.concat(book_list, ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T21:58:14.981443Z","iopub.execute_input":"2025-04-30T21:58:14.981810Z","iopub.status.idle":"2025-04-30T21:58:25.951537Z","shell.execute_reply.started":"2025-04-30T21:58:14.981786Z","shell.execute_reply":"2025-04-30T21:58:25.950575Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"book_raw['mid_price'] = 0.5 * (book_raw['ask_price1'] + book_raw['bid_price1'])\n\nfirst_last = (\n    book_raw.sort_values(['stock_id', 'time_id', 'seconds_in_bucket'])\n            .groupby(['stock_id', 'time_id'])['mid_price']\n            .agg(mid_price_first='first', mid_price_last='last')\n            .reset_index()\n)\n\nfirst_last['mid_price_change'] = (\n    first_last['mid_price_last'] / first_last['mid_price_first'] - 1.0\n)\n\ndata = data.merge(\n    first_last[['stock_id', 'time_id', 'mid_price_change']],\n    on=['stock_id', 'time_id'],\n    how='left'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T21:59:29.544905Z","iopub.execute_input":"2025-04-30T21:59:29.545251Z","iopub.status.idle":"2025-04-30T22:00:06.617565Z","shell.execute_reply.started":"2025-04-30T21:59:29.545227Z","shell.execute_reply":"2025-04-30T22:00:06.615954Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"- list features to use in the model.\n- Build matrices: X = features, y = target, groups = time_id for CV.\n- Set up time-aware CV (GroupKFold(n_splits=3)).\n- Define RMSPE metric.\n- Print fold sizes, quick check that each split has balanced train/val rows.","metadata":{}},{"cell_type":"code","source":"feature_cols = [\n    \"avg_spread\",\n    \"mid_price_vol\",\n    \"order_imbalance\",\n    \"trade_logret_std\",\n    'mid_price_change',\n    'stock_mean_target' \n]\n\nX = data[feature_cols]\ny = data[\"target\"]\ngroups = data[\"time_id\"]  \n\ngkf = GroupKFold(n_splits=3)\n\ndef rmspe(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n\nfor i, (tr_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n    print(f\"Fold {i}: train={len(tr_idx):,}  val={len(val_idx):,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T22:05:18.731008Z","iopub.execute_input":"2025-04-30T22:05:18.731317Z","iopub.status.idle":"2025-04-30T22:05:18.851921Z","shell.execute_reply.started":"2025-04-30T22:05:18.731295Z","shell.execute_reply":"2025-04-30T22:05:18.850770Z"}},"outputs":[{"name":"stdout","text":"Fold 0: train=286,028  val=142,904\nFold 1: train=285,918  val=143,014\nFold 2: train=285,918  val=143,014\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"- Set up LightGBM grid search: Three parameter combos with deeper trees and varied leaf sizes.\n- Loop over param sets: For each, perform 3-fold GroupKFold training/validation.\n- Early-stopping & logging: Stops after 50 no-gain rounds, prints progress every 200 iters.\n- Collect out-of-fold (OOF) predictions\n- Track best model: Keeps lowest RMSPE and its parameters, prints final best score.","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb \nfrom lightgbm import early_stopping, log_evaluation\n\nparam_grid = [\n    {'num_leaves': 127, 'min_data_in_leaf': 50,  'learning_rate': 0.02, 'feature_fraction': 0.8},\n    {'num_leaves': 127, 'min_data_in_leaf': 100, 'learning_rate': 0.02, 'feature_fraction': 0.8},\n    {'num_leaves': 255, 'min_data_in_leaf': 50,  'learning_rate': 0.015,'feature_fraction': 0.75},\n]\n\ndef rmspe(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n\nbest_score = np.inf\nbest_params = None\n\nfor params in param_grid:\n    print(f\"Testing params: {params}\")\n    \n    oof_pred = np.zeros(len(y))\n    \n    for fold, (tr_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n        \n        lgb_train = lgb.Dataset(X_tr, y_tr)\n        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n        \n        full_params = {\n            'objective': 'regression',\n            'metric':    'rmse',\n            'verbosity': -1,\n            **params\n        }\n        \n        model = lgb.train(\n            params = full_params,\n            train_set = lgb_train,\n            num_boost_round = 5000,\n            valid_sets = [lgb_val],\n            callbacks = [\n                early_stopping(stopping_rounds=50),\n                log_evaluation(period=200) \n            ]\n        )\n        \n        oof_pred[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n        print(f\" Fold {fold} done. Best iters: {model.best_iteration}\")\n    \n    score = rmspe(y, oof_pred)\n    print(f\"OOF RMSPE for params {params}: {score:}\")\n    \n    if score < best_score:\n        best_score, best_params = score, params\n\nprint(\"\\n==============================\")\nprint(f\"Best RMSPE: {best_score:}\")\nprint(f\"Best params: {best_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T22:08:09.628346Z","iopub.execute_input":"2025-04-30T22:08:09.628742Z","iopub.status.idle":"2025-04-30T22:11:47.329312Z","shell.execute_reply.started":"2025-04-30T22:08:09.628712Z","shell.execute_reply":"2025-04-30T22:11:47.328254Z"}},"outputs":[{"name":"stdout","text":"Testing params: {'num_leaves': 127, 'min_data_in_leaf': 50, 'learning_rate': 0.02, 'feature_fraction': 0.8}\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00150657\n[400]\tvalid_0's rmse: 0.00148638\n[600]\tvalid_0's rmse: 0.00148274\nEarly stopping, best iteration is:\n[728]\tvalid_0's rmse: 0.00148217\n Fold 0 done. Best iters: 728\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00159725\n[400]\tvalid_0's rmse: 0.00157153\n[600]\tvalid_0's rmse: 0.00156668\nEarly stopping, best iteration is:\n[711]\tvalid_0's rmse: 0.00156573\n Fold 1 done. Best iters: 711\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00144533\n[400]\tvalid_0's rmse: 0.00142825\n[600]\tvalid_0's rmse: 0.00142548\nEarly stopping, best iteration is:\n[717]\tvalid_0's rmse: 0.00142485\n Fold 2 done. Best iters: 717\nOOF RMSPE for params {'num_leaves': 127, 'min_data_in_leaf': 50, 'learning_rate': 0.02, 'feature_fraction': 0.8}: 0.36505301436574605\nTesting params: {'num_leaves': 127, 'min_data_in_leaf': 100, 'learning_rate': 0.02, 'feature_fraction': 0.8}\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00150652\n[400]\tvalid_0's rmse: 0.0014866\n[600]\tvalid_0's rmse: 0.00148311\nEarly stopping, best iteration is:\n[740]\tvalid_0's rmse: 0.0014821\n Fold 0 done. Best iters: 740\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00159815\n[400]\tvalid_0's rmse: 0.00157188\n[600]\tvalid_0's rmse: 0.00156714\nEarly stopping, best iteration is:\n[691]\tvalid_0's rmse: 0.00156625\n Fold 1 done. Best iters: 691\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00144525\n[400]\tvalid_0's rmse: 0.00142905\n[600]\tvalid_0's rmse: 0.00142514\n[800]\tvalid_0's rmse: 0.0014244\nEarly stopping, best iteration is:\n[891]\tvalid_0's rmse: 0.00142423\n Fold 2 done. Best iters: 891\nOOF RMSPE for params {'num_leaves': 127, 'min_data_in_leaf': 100, 'learning_rate': 0.02, 'feature_fraction': 0.8}: 0.3633376542619523\nTesting params: {'num_leaves': 255, 'min_data_in_leaf': 50, 'learning_rate': 0.015, 'feature_fraction': 0.75}\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00151522\n[400]\tvalid_0's rmse: 0.00148912\n[600]\tvalid_0's rmse: 0.0014861\nEarly stopping, best iteration is:\n[707]\tvalid_0's rmse: 0.00148572\n Fold 0 done. Best iters: 707\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00161183\n[400]\tvalid_0's rmse: 0.00157377\n[600]\tvalid_0's rmse: 0.00156833\n[800]\tvalid_0's rmse: 0.00156739\nEarly stopping, best iteration is:\n[783]\tvalid_0's rmse: 0.00156735\n Fold 1 done. Best iters: 783\nTraining until validation scores don't improve for 50 rounds\n[200]\tvalid_0's rmse: 0.00145202\n[400]\tvalid_0's rmse: 0.00143134\n[600]\tvalid_0's rmse: 0.00142794\nEarly stopping, best iteration is:\n[691]\tvalid_0's rmse: 0.00142775\n Fold 2 done. Best iters: 691\nOOF RMSPE for params {'num_leaves': 255, 'min_data_in_leaf': 50, 'learning_rate': 0.015, 'feature_fraction': 0.75}: 0.36475520161366143\n\n==============================\nBest RMSPE: 0.3633376542619523\nBest params: {'num_leaves': 127, 'min_data_in_leaf': 100, 'learning_rate': 0.02, 'feature_fraction': 0.8}\n","output_type":"stream"}],"execution_count":47}]}
